{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.31.3.150:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_id = 'AKIAJXBU2EK4HLF5SVHA'\n",
    "access_key = 't03HUEi4mBGutI+pARJVYEyi+RZSBZXOpdLc3xLr'\n",
    "region = \"us-east-2\"\n",
    "sc.setSystemProperty(\"com.amazonaws.services.s3.enableV4\",   \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsAccessKeyId\",   key_id)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsSecretAccessKey\",   access_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\",   \"s3.\"   +   region   +   \".amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc.textFile(\"s3a://ids-2017-group41-test/test.txt\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sc.textFile(\"s3a://sandeepb92/text.txt\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sql = SQLContext(sc)\n",
    "\n",
    "# df = (sql.read\n",
    "#          .format(\"com.databricks.spark.csv\")\n",
    "#          .option(\"header\", \"true\")\n",
    "#          .load(\"s3a://ids-2017-group42/train_ver2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_df = spark.read.option(\"header\", \"true\").csv(\"s3a://ids-2017-group42/train_ver2.csv\")\n",
    "base_df = base_df.limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_time: string (nullable = true)\n",
      " |-- site_name: string (nullable = true)\n",
      " |-- posa_continent: string (nullable = true)\n",
      " |-- user_location_country: string (nullable = true)\n",
      " |-- user_location_region: string (nullable = true)\n",
      " |-- user_location_city: string (nullable = true)\n",
      " |-- orig_destination_distance: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- is_mobile: string (nullable = true)\n",
      " |-- is_package: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- srch_ci: string (nullable = true)\n",
      " |-- srch_co: string (nullable = true)\n",
      " |-- srch_adults_cnt: string (nullable = true)\n",
      " |-- srch_children_cnt: string (nullable = true)\n",
      " |-- srch_rm_cnt: string (nullable = true)\n",
      " |-- srch_destination_id: string (nullable = true)\n",
      " |-- srch_destination_type_id: string (nullable = true)\n",
      " |-- is_booking: string (nullable = true)\n",
      " |-- cnt: string (nullable = true)\n",
      " |-- hotel_continent: string (nullable = true)\n",
      " |-- hotel_country: string (nullable = true)\n",
      " |-- hotel_market: string (nullable = true)\n",
      " |-- hotel_cluster: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting date_time column into a date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DateType\n",
    "\n",
    "conv_to_date = udf(lambda x: datetime.strptime(x[:10], '%Y-%m-%d'), DateType())\n",
    "base_df = base_df.withColumn(\"Date\", conv_to_date(col('date_time')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_df.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_time: string (nullable = true)\n",
      " |-- site_name: string (nullable = true)\n",
      " |-- posa_continent: string (nullable = true)\n",
      " |-- user_location_country: string (nullable = true)\n",
      " |-- user_location_region: string (nullable = true)\n",
      " |-- user_location_city: string (nullable = true)\n",
      " |-- orig_destination_distance: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- is_mobile: string (nullable = true)\n",
      " |-- is_package: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- srch_ci: string (nullable = true)\n",
      " |-- srch_co: string (nullable = true)\n",
      " |-- srch_adults_cnt: string (nullable = true)\n",
      " |-- srch_children_cnt: string (nullable = true)\n",
      " |-- srch_rm_cnt: string (nullable = true)\n",
      " |-- srch_destination_id: string (nullable = true)\n",
      " |-- srch_destination_type_id: string (nullable = true)\n",
      " |-- is_booking: string (nullable = true)\n",
      " |-- cnt: string (nullable = true)\n",
      " |-- hotel_continent: string (nullable = true)\n",
      " |-- hotel_country: string (nullable = true)\n",
      " |-- hotel_market: string (nullable = true)\n",
      " |-- hotel_cluster: string (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Season column for applying filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnSeason(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_location_city='48862')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row5_df = base_df.select('user_location_city').limit(10000)\n",
    "row5_df.take(1)\n",
    "\n",
    "# row1_rdd = base_rdd.map(lambda x: Vectors.dense(int(x[5])))\n",
    "# # row1_rdd.saveAsTextFile(\"s3a://ids-2017-group41-test/row1.txt\")\n",
    "# type(row1_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# converting data type string to double.\n",
    "from pyspark.sql.types import DoubleType\n",
    "row_5_preassembler = row5_df.withColumn(\"user_location_city\", row5_df[\"user_location_city\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row5_df_assembler = VectorAssembler(\n",
    "        inputCols=['user_location_city'],\n",
    "        outputCol=\"features\")\n",
    "\n",
    "row_df_assembled = row5_df_assembler.transform(row_5_preassembler)\n",
    "row_df_assembled.take(1)\n",
    "\n",
    "# summary = Statistics.colStats(row1_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(row_df_assembled.select('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('date_time', 'string'),\n",
       " ('site_name', 'string'),\n",
       " ('posa_continent', 'string'),\n",
       " ('user_location_country', 'string'),\n",
       " ('user_location_region', 'string'),\n",
       " ('user_location_city', 'string'),\n",
       " ('orig_destination_distance', 'string'),\n",
       " ('user_id', 'string'),\n",
       " ('is_mobile', 'string'),\n",
       " ('is_package', 'string'),\n",
       " ('channel', 'string'),\n",
       " ('srch_ci', 'string'),\n",
       " ('srch_co', 'string'),\n",
       " ('srch_adults_cnt', 'string'),\n",
       " ('srch_children_cnt', 'string'),\n",
       " ('srch_rm_cnt', 'string'),\n",
       " ('srch_destination_id', 'string'),\n",
       " ('srch_destination_type_id', 'string'),\n",
       " ('is_booking', 'string'),\n",
       " ('cnt', 'string'),\n",
       " ('hotel_continent', 'string'),\n",
       " ('hotel_country', 'string'),\n",
       " ('hotel_market', 'string'),\n",
       " ('hotel_cluster', 'string')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hotel_cluster='1')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.select('hotel_cluster').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row_df_mapped = row_df_assembled.rdd.map(lambda row: Vectors.dense([x for x in row['features']]))\n",
    "type(row_df_mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = Statistics.colStats(row_df_mapped)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
